{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Download model and data\n",
    "!mkdir -p cache\n",
    "!curl -Lo \"cache/cache_r0_vbp.h5\" \"https://pub-2fdef7a2969f43289c42ac5ae3412fd4.r2.dev/cache_r0_vbp.h5\"\n",
    "!curl -Lo \"cache/cache_r1_vbp.h5\" \"https://pub-2fdef7a2969f43289c42ac5ae3412fd4.r2.dev/cache_r1_vbp.h5\"\n",
    "!pip install -q safetensors diffusers omegaconf accelerate\n",
    "\n",
    "# restart runtime\n",
    "exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Functions\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "# Hide welcome message from bitsandbytes\n",
    "os.environ.update({\"BITSANDBYTES_NOWELCOME\": \"1\"})\n",
    "\n",
    "import h5py, random, torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path  \n",
    "from torchvision import transforms\n",
    "from diffusers import AutoencoderKL\n",
    "\n",
    "# Load the model\n",
    "vae = AutoencoderKL.from_pretrained(\"nyanko7/sdxl-vae-0.9\")\n",
    "vae.eval().cuda()\n",
    "vae.requires_grad_(False)\n",
    "\n",
    "def denormalize(img, mean=0.5, std=0.5):\n",
    "    res = transforms.Normalize((-1*mean/std), (1.0/std))(img)\n",
    "    res = torch.clamp(res, 0, 1)\n",
    "    return res\n",
    "\n",
    "def create_vds_for_group(source_group, target_group, bar):\n",
    "    for key, item in source_group.items():\n",
    "        if key in target_group:\n",
    "            if key.endswith(\".latents\"):\n",
    "                bar.update(1)\n",
    "            continue\n",
    "        layout = h5py.VirtualLayout(shape=item.shape, dtype=item.dtype)\n",
    "        layout[:] = h5py.VirtualSource(item)\n",
    "        target_group.create_virtual_dataset(key, layout)\n",
    "        if key.endswith(\".latents\"):\n",
    "            bar.update(1)\n",
    "\n",
    "# Load latents from the h5 file\n",
    "def load_latents_from_h5(h5_path, hashsum=None):\n",
    "    cache_parts = list(Path(h5_path).glob(\"*.h5\"))\n",
    "    with h5py.File(\"cache_index.tmp\", 'a', libver='latest', driver='core') as fo:  # using 'latest' for VDS support\n",
    "        bar = tqdm(desc=\"Creating index\")\n",
    "        for input_file in cache_parts:\n",
    "            with h5py.File(input_file, 'r') as fi:\n",
    "                create_vds_for_group(fi, fo, bar)\n",
    "                \n",
    "    with h5py.File(\"cache_index.tmp\", 'r') as f:\n",
    "        # Get all datasets keys that match the pattern\n",
    "        keys = [key for key in f.keys() if key.endswith(\".latents\")]\n",
    "        chosen_key = hashsum\n",
    "        if chosen_key is None:\n",
    "            chosen_key = random.choice(keys)\n",
    "            \n",
    "        if (Path(h5_path) / \"dataset.json\").exists():\n",
    "            import json\n",
    "            with open(Path(h5_path) / \"dataset.json\", \"r\") as f2:\n",
    "                dataset = json.load(f2)\n",
    "                print(json.dumps(dataset[chosen_key[:-8]], indent=2))\n",
    "        latents = f[chosen_key][:]\n",
    "        return torch.asarray(latents).cuda().to(torch.float32)\n",
    "\n",
    "def inspect(path=\"cache\", hashsum=None):\n",
    "    # Define path to h5 file containing latents\n",
    "    latents = load_latents_from_h5(path, hashsum)\n",
    "\n",
    "    # Decode latents\n",
    "    print(f\"stat: {latents.mean()}, {latents.std()}\")\n",
    "    latents = latents.unsqueeze(0)\n",
    "    \n",
    "    # latents = 1.0 / 0.13025 * latents\n",
    "    with torch.no_grad():\n",
    "        img_decoded = vae.decode(latents).sample\n",
    "\n",
    "    # Convert tensors to numpy arrays for visualization\n",
    "    img_decoded = denormalize(img_decoded).squeeze().permute(1, 2, 0).cpu().numpy()\n",
    "\n",
    "    # Display the decoded image\n",
    "    plt.figure(dpi=300)\n",
    "    plt.imshow(img_decoded)\n",
    "    plt.axis('off')  # turn off the axis\n",
    "    plt.title('Decoded from Latents', fontsize=4)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Inspect\n",
    "inspect(path=\"/notebooks/BA_latents\", hashsum=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
