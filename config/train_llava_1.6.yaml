name: test-run
target: modules.train_llava.setup

model_params:
  attn_implementation: sdpa
  # attn_implementation: flash_attention_2

# pretrain config
# model_config:
#   version: vicuna_v1
#   image_aspect_ratio: "anyres"
#   image_crop_resolution: 224
#   image_split_resolution: 224
#   mm_hidden_size: 1024
#   mm_patch_merge_type: "spatial_unpad"
#   mm_projector_lr: null
#   mm_projector_type: "mlp2x_gelu"
#   mm_resampler_type: null
#   mm_use_im_patch_token: false
#   mm_use_im_start_end: false
#   mm_vision_select_feature: "patch"
#   mm_vision_select_layer: -2
#   mm_vision_tower: "openai/clip-vit-large-patch14-336"
#   mm_vision_tower_lr: 2e-06
#   tune_mm_mlp_adapter: true
#   tune_mm_vision_tower: false
#   freeze_backbone: true
#   lazyload_vision_tower: false
#   image_grid_pinpoints: [[336, 672], [672, 336], [672, 672], [1008, 336], [336, 1008]]

# finetune config
model_config:
  version: vicuna_v1 # chatml_direct for 34b
  image_aspect_ratio: "anyres"
  image_crop_resolution: 224
  image_split_resolution: 224
  mm_hidden_size: 1024
  mm_patch_merge_type: "spatial_unpad"
  mm_projector_lr: null
  mm_projector_type: "mlp2x_gelu"
  mm_resampler_type: null
  mm_use_im_patch_token: false
  mm_use_im_start_end: false
  mm_vision_select_feature: "patch"
  mm_vision_select_layer: -2
  mm_vision_tower: "openai/clip-vit-large-patch14-336"
  mm_vision_tower_lr: 2e-06
  tune_mm_mlp_adapter: false
  tune_mm_vision_tower: true
  freeze_backbone: false
  lazyload_vision_tower: true
  image_grid_pinpoints: [[336, 672], [672, 336], [672, 672], [1008, 336], [336, 1008]]

use_lora: true
q_lora: false
lora_params:
  r: 128
  lora_alpha: 256
  target_modules: ... # will inherit from the model_params
  lora_dropout: 0.05
  bias: "none"
  task_type: "CAUSAL_LM"

trainer:
  model_path: lmsys/vicuna-13b-v1.5
  batch_size: 32
  seed: 1138
  wandb_id: "qwen"
  accumulate_grad_batches: 1
  gradient_clip_val: 1.0

  save_format: diffusers
  checkpoint_dir: checkpoint
  checkpoint_freq: 1
  checkpoint_steps: 5000
  save_weights_only: True
  eval_samples: 1000
  eval_steps: 1000
  eval_epoch: 1
  max_epochs: 60
  max_steps: -1
  
lightning:
  accelerator: gpu
  devices: -1
  precision: bf16-true

dataset:
  name: data.llava_dataset.LazySupervisedDataset
  model_max_length: 4096
  data_path: /home/ubuntu/llava/blip_laion_cc_sbu_558k.json
  image_folder: /home/ubuntu/llava/
  
optimizer:
  name: bitsandbytes.optim.AdamW8bit
  params:
    lr: 4e-5
    weight_decay: 1e-2

scheduler:
  name: transformers.get_cosine_schedule_with_warmup
  params:
    num_training_steps: 5000
    num_warmup_steps: 50
    last_epoch: -1

sampling:
  enabled: false
  max_length: 200
  every_n_steps: 50
  every_n_epochs: 1
  prompts:
    - "what is the result of 1+1"
    - "what is the result of 2*591"
    - "what is the result of 3^2"
    - "what is the result of sqrt(128)"
